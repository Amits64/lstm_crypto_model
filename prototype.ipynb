{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28527e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "from config import HEADERS, CSV_DOWNLOAD_URL, DHAN_SCRIP_MASTER_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90f907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dhan CSV...\n",
      "✅ Dhan CSV download completed.\n",
      "\n",
      "Fetching NIFTY 50 symbols...\n",
      "✅ NIFTY 50 Symbols (50):\n",
      "['ADANIENT.NS', 'ADANIPORTS.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS', 'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJFINANCE.NS', 'BAJAJFINSV.NS', 'BEL.NS', 'BHARTIARTL.NS', 'CIPLA.NS', 'COALINDIA.NS', 'DRREDDY.NS', 'EICHERMOT.NS', 'ETERNAL.NS', 'GRASIM.NS', 'HCLTECH.NS', 'HDFCBANK.NS', 'HDFCLIFE.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'HINDUNILVR.NS', 'ICICIBANK.NS', 'ITC.NS', 'INDUSINDBK.NS', 'INFY.NS', 'JSWSTEEL.NS', 'JIOFIN.NS', 'KOTAKBANK.NS', 'LT.NS', 'M&M.NS', 'MARUTI.NS', 'NTPC.NS', 'NESTLEIND.NS', 'ONGC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBILIFE.NS', 'SHRIRAMFIN.NS', 'SBIN.NS', 'SUNPHARMA.NS', 'TCS.NS', 'TATACONSUM.NS', 'TATAMOTORS.NS', 'TATASTEEL.NS', 'TECHM.NS', 'TITAN.NS', 'TRENT.NS', 'ULTRACEMCO.NS', 'WIPRO.NS']\n"
     ]
    }
   ],
   "source": [
    "# Initialize session\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "def download_dhan_csv():\n",
    "    \"\"\"Download the Dhan scrip master CSV.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(CSV_DOWNLOAD_URL, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        with open(DHAN_SCRIP_MASTER_CSV, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        logging.info(\"✅ Dhan CSV downloaded successfully.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Failed downloading Dhan CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "def fetch_nifty50_symbols():\n",
    "    \"\"\"Fetch the latest list of Nifty50 stock symbols.\"\"\"\n",
    "    try:\n",
    "        r = session.get(\"https://nsearchives.nseindia.com/content/indices/ind_nifty50list.csv\", timeout=30)\n",
    "        r.raise_for_status()\n",
    "        df = pd.read_csv(io.StringIO(r.text))\n",
    "        return (df[\"Symbol\"] + \".NS\").tolist()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching Nifty50 symbols: {e}\")\n",
    "        return []\n",
    "\n",
    "# 🟢 Display output\n",
    "print(\"Downloading Dhan CSV...\")\n",
    "if download_dhan_csv():\n",
    "    print(\"✅ Dhan CSV download completed.\\n\")\n",
    "\n",
    "print(\"Fetching NIFTY 50 symbols...\")\n",
    "symbols = fetch_nifty50_symbols()\n",
    "print(f\"✅ NIFTY 50 Symbols ({len(symbols)}):\\n{symbols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8c9e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chauh\\AppData\\Local\\Temp\\ipykernel_24612\\2660403040.py:1: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/api-scrip-master.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SM_SYMBOL_NAME       SEM_TRADING_SYMBOL      SEM_EXPIRY_DATE  \\\n",
      "36697         BSXOPT  SENSEX-Jun2030-84000-PE  2030-06-27 15:30:00   \n",
      "36585         BSXOPT  SENSEX-Jun2030-81000-PE  2030-06-27 15:30:00   \n",
      "36342         BSXOPT  SENSEX-Jun2030-88000-PE  2030-06-27 15:30:00   \n",
      "36344         BSXOPT  SENSEX-Jun2030-82000-PE  2030-06-27 15:30:00   \n",
      "36349         BSXOPT  SENSEX-Jun2030-85000-CE  2030-06-27 15:30:00   \n",
      "\n",
      "      SEM_OPTION_TYPE  \n",
      "36697              PE  \n",
      "36585              PE  \n",
      "36342              PE  \n",
      "36344              PE  \n",
      "36349              CE  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/api-scrip-master.csv\")\n",
    "\n",
    "options_df = df[df['SEM_INSTRUMENT_NAME'].str.contains(\"OPT\")]\n",
    "options_df = options_df[options_df['SEM_OPTION_TYPE'].isin(['CE', 'PE']) & options_df['SEM_EXPIRY_DATE'].notna()]\n",
    "latest_options = options_df.sort_values('SEM_EXPIRY_DATE', ascending=False).groupby('SM_SYMBOL_NAME').head(10)\n",
    "\n",
    "print(latest_options[['SM_SYMBOL_NAME', 'SEM_TRADING_SYMBOL', 'SEM_EXPIRY_DATE', 'SEM_OPTION_TYPE']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d24f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Open         High          Low        Close   Volume\n",
      "Datetime                                                                     \n",
      "2025-04-17 10:15  1229.800049  1242.400024  1229.199951  1242.099976  1519469\n",
      "2025-04-17 11:15  1242.300049  1260.000000  1242.199951  1259.000000  2433094\n",
      "2025-04-17 12:15  1259.000000  1267.500000  1258.300049  1267.300049  1913242\n",
      "2025-04-17 13:15  1267.400024  1277.599976  1265.300049  1275.000000  3139558\n",
      "2025-04-17 14:15  1275.000000  1278.300049  1272.000000  1273.500000  3532377\n",
      "...                       ...          ...          ...          ...      ...\n",
      "2025-07-16 11:15  1480.000000  1483.699951  1476.500000  1483.000000  1068791\n",
      "2025-07-16 12:15  1483.300049  1485.400024  1479.900024  1480.699951  1582096\n",
      "2025-07-16 13:15  1480.699951  1485.000000  1479.400024  1485.000000   916879\n",
      "2025-07-16 14:15  1485.000000  1491.000000  1484.000000  1485.099976  2443017\n",
      "2025-07-16 15:15  1485.400024  1486.800049  1484.400024  1486.199951   954274\n",
      "\n",
      "[396 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Example: Fetch 3 months of 1-day interval price data\n",
    "df = yf.Ticker(\"RELIANCE.NS\").history(period=\"3mo\", interval=\"1h\")\n",
    "df = df[df['Volume'] > 0]\n",
    "df = df[['Open', 'High', 'Low', 'Close', 'Volume']]  # keep required columns\n",
    "df.index = df.index.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e0e11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  CDL2CROWS  CDL3BLACKCROWS  CDL3INSIDE  CDL3LINESTRIKE  \\\n",
      "Datetime                                                                  \n",
      "2025-04-17 10:15          0               0           0               0   \n",
      "2025-04-17 11:15          0               0           0               0   \n",
      "2025-04-17 12:15          0               0           0               0   \n",
      "2025-04-17 13:15          0               0           0               0   \n",
      "2025-04-17 14:15          0               0           0               0   \n",
      "\n",
      "                  CDL3OUTSIDE  CDL3STARSINSOUTH  CDL3WHITESOLDIERS  \\\n",
      "Datetime                                                             \n",
      "2025-04-17 10:15            0                 0                  0   \n",
      "2025-04-17 11:15            0                 0                  0   \n",
      "2025-04-17 12:15            0                 0                  0   \n",
      "2025-04-17 13:15            0                 0                  0   \n",
      "2025-04-17 14:15            0                 0                  0   \n",
      "\n",
      "                  CDLABANDONEDBABY  CDLADVANCEBLOCK  CDLBELTHOLD  ...  \\\n",
      "Datetime                                                          ...   \n",
      "2025-04-17 10:15                 0                0            0  ...   \n",
      "2025-04-17 11:15                 0                0            0  ...   \n",
      "2025-04-17 12:15                 0                0            0  ...   \n",
      "2025-04-17 13:15                 0                0            0  ...   \n",
      "2025-04-17 14:15                 0                0            0  ...   \n",
      "\n",
      "                  CDLSPINNINGTOP  CDLSTALLEDPATTERN  CDLSTICKSANDWICH  \\\n",
      "Datetime                                                                \n",
      "2025-04-17 10:15               0                  0                 0   \n",
      "2025-04-17 11:15               0                  0                 0   \n",
      "2025-04-17 12:15               0                  0                 0   \n",
      "2025-04-17 13:15               0                  0                 0   \n",
      "2025-04-17 14:15               0                  0                 0   \n",
      "\n",
      "                  CDLTAKURI  CDLTASUKIGAP  CDLTHRUSTING  CDLTRISTAR  \\\n",
      "Datetime                                                              \n",
      "2025-04-17 10:15          0             0             0           0   \n",
      "2025-04-17 11:15          0             0             0           0   \n",
      "2025-04-17 12:15          0             0             0           0   \n",
      "2025-04-17 13:15          0             0             0           0   \n",
      "2025-04-17 14:15          0             0             0           0   \n",
      "\n",
      "                  CDLUNIQUE3RIVER  CDLUPSIDEGAP2CROWS  CDLXSIDEGAP3METHODS  \n",
      "Datetime                                                                    \n",
      "2025-04-17 10:15                0                   0                    0  \n",
      "2025-04-17 11:15                0                   0                    0  \n",
      "2025-04-17 12:15                0                   0                    0  \n",
      "2025-04-17 13:15                0                   0                    0  \n",
      "2025-04-17 14:15                0                   0                    0  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import talib\n",
    "\n",
    "def add_cdl_patterns(df):\n",
    "    patterns = [f for f in dir(talib) if f.startswith('CDL')]\n",
    "    for pattern in patterns:\n",
    "        try:\n",
    "            df[pattern] = getattr(talib, pattern)(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "        except:\n",
    "            df[pattern] = 0\n",
    "    return df\n",
    "\n",
    "df = add_cdl_patterns(df)\n",
    "# print(df[[col for col in df.columns if col.startswith(\"CDL\")]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3eb7c6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              BOS  OrderBlock  LiquiditySweep  CHoCH\n",
      "2025-07-16  False       False           False   True\n",
      "2025-07-16  False        True           False  False\n",
      "2025-07-16  False       False           False  False\n",
      "2025-07-16  False       False           False   True\n",
      "2025-07-16  False       False           False  False\n"
     ]
    }
   ],
   "source": [
    "def detect_smc_features(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'BOS'] = df['High'].gt(df['High'].shift(1)) & df['Low'].lt(df['Low'].shift(1))\n",
    "    df.loc[:, 'OrderBlock'] = (df['Close'] < df['Open']) & (df['Volume'] > df['Volume'].rolling(5).mean())\n",
    "    df.loc[:, 'LiquiditySweep'] = df['Low'] < df['Low'].rolling(10).min()\n",
    "    df.loc[:, 'CHoCH'] = df['Close'] > df['High'].shift(1)\n",
    "    return df\n",
    "\n",
    "df.index = pd.to_datetime(df.index).date\n",
    "\n",
    "df = detect_smc_features(df)\n",
    "print(df[['BOS', 'OrderBlock', 'LiquiditySweep', 'CHoCH']].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f22471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ATR        RSI      MACD     BB_upper     BB_lower  \\\n",
      "2025-07-16  7.112575  37.694596 -8.145176  1492.213670  1473.466310   \n",
      "2025-07-16  6.997391  35.971703 -7.976028  1489.953915  1473.166055   \n",
      "2025-07-16  6.897576  41.367306 -7.409586  1487.139633  1474.580337   \n",
      "2025-07-16  6.904892  41.490758 -6.873378  1487.026895  1478.453085   \n",
      "2025-07-16  6.583116  42.914904 -6.287195  1487.892538  1480.107413   \n",
      "\n",
      "             Volume_MA  \n",
      "2025-07-16  1269433.10  \n",
      "2025-07-16  1300615.90  \n",
      "2025-07-16  1316595.85  \n",
      "2025-07-16  1409042.75  \n",
      "2025-07-16  1364160.50  \n"
     ]
    }
   ],
   "source": [
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    df['ATR'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "    df['RSI'] = talib.RSI(df['Close'], timeperiod=14)\n",
    "    df['MACD'], _, _ = talib.MACD(df['Close'])\n",
    "    df['BB_upper'], df['BB_middle'], df['BB_lower'] = talib.BBANDS(df['Close'])\n",
    "    df['Volume_MA'] = df['Volume'].rolling(20).mean()\n",
    "    return df\n",
    "\n",
    "df = engineer_features(df)\n",
    "print(df[['ATR', 'RSI', 'MACD', 'BB_upper', 'BB_lower', 'Volume_MA']].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8eaf86a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Close  future_return  target\n",
      "2025-07-14  1483.400024       0.002697       0\n",
      "2025-07-14  1485.599976       0.001010       0\n",
      "2025-07-15  1493.400024      -0.003281       0\n",
      "2025-07-15  1492.699951      -0.011389       0\n",
      "2025-07-15  1489.199951      -0.006245       0\n",
      "2025-07-15  1487.400024      -0.002958       0\n",
      "2025-07-15  1487.099976      -0.004304       0\n",
      "2025-07-15  1488.500000      -0.002351       0\n",
      "2025-07-16  1475.699951       0.006370       0\n",
      "2025-07-16  1479.900024       0.004257       0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def label_targets(df, horizon=5, threshold=0.02):\n",
    "    df['future_return'] = df['Close'].shift(-horizon) / df['Close'] - 1\n",
    "    df['target'] = np.where(df['future_return'] > threshold, 1, 0)\n",
    "    df['target'] = np.where(df['future_return'] < -threshold, -1, df['target'])  # -1 = sell, 1 = buy\n",
    "    return df\n",
    "\n",
    "df = label_targets(df, horizon=5, threshold=0.02).dropna()\n",
    "print(df[['Close', 'future_return', 'target']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7ca2d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained with accuracy: 93.75%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(df):\n",
    "    df = df.copy()\n",
    "    df = engineer_features(add_cdl_patterns(detect_smc_features(df)))\n",
    "    df = label_targets(df)\n",
    "    df = df.dropna()\n",
    "\n",
    "    features = [col for col in df.columns if col not in ['target', 'future_return']]\n",
    "    X, y = df[features], df['target']\n",
    "    y = y.replace({-1: 0, 0: 1, 1: 2})  # remap: 0=Sell, 1=Hold, 2=Buy\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "    \n",
    "    model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.05)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"✅ Model trained with accuracy: {accuracy:.2%}\")\n",
    "\n",
    "    return model, features  # ⬅ return features too\n",
    "\n",
    "model = train_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "123121ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained with accuracy: 92.19%\n",
      "🔔 Signal: Hold\n"
     ]
    }
   ],
   "source": [
    "def generate_signal(model, latest_df, trained_features):\n",
    "    latest_df = engineer_features(add_cdl_patterns(detect_smc_features(latest_df)))\n",
    "    features = latest_df.iloc[-1:][trained_features]\n",
    "    pred = model.predict(features)[0]\n",
    "    return {0: 'Sell', 1: 'Hold', 2: 'Buy'}.get(pred, 'Hold')\n",
    "\n",
    "model, trained_features = train_model(df)\n",
    "signal = generate_signal(model, df, trained_features)\n",
    "print(f\"🔔 Signal: {signal}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
